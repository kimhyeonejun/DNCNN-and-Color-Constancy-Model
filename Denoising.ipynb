{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAemurmrYhY_",
        "outputId": "84c36492-4003-4d24-e6d4-23ae37e05c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFNtIhGp77W2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.utils.data as data\n",
        "from os.path import join\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "from torchvision.transforms import *\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in [\".png\", \".jpg\", \".jpeg\",\".bmp\"])\n",
        "\n",
        "def load_img(filepath, ch):\n",
        "    if ch == 1:\n",
        "      img = Image.open(filepath)#.convert('RGB')\n",
        "    elif ch == 3:\n",
        "      img = Image.open(filepath).convert('RGB')\n",
        "    return img\n",
        "\n",
        "class DatasetFromFolder(data.Dataset):\n",
        "    def __init__(self, data_dir, patch_size, sigma, ch):\n",
        "        super(DatasetFromFolder, self).__init__()\n",
        "        self.image_filenames = [join(data_dir, data) for data in listdir(data_dir) if is_image_file(data)]\n",
        "        self.patch_size = patch_size\n",
        "        self.sigma = sigma\n",
        "        self.ch = ch\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_x = load_img(self.image_filenames[index], self.ch)\n",
        "\n",
        "        img_x = transforms.ToTensor()(img_x)\n",
        "        _, h, w = img_x.shape\n",
        "        ih = np.random.randint(0, h - self.patch_size)\n",
        "        iw = np.random.randint(0, w - self.patch_size)\n",
        "\n",
        "        img_x = img_x[:, ih:ih + self.patch_size, iw:iw + self.patch_size]\n",
        "        noise = torch.randn(img_x.size()).mul_(self.sigma/255.0)\n",
        "        img_y = img_x + noise\n",
        "\n",
        "        return img_y, img_x\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "class DatasetFromFolderEval(data.Dataset):\n",
        "    def __init__(self, data_dir, sigma, ch):\n",
        "        super(DatasetFromFolderEval, self).__init__()\n",
        "        self.image_filenames = [join(data_dir, data) for data in listdir(data_dir) if is_image_file(data)]\n",
        "        self.sigma = sigma\n",
        "        self.ch = ch\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path, file = os.path.split(self.image_filenames[index])\n",
        "        img_x = load_img(self.image_filenames[index], self.ch)\n",
        "\n",
        "        img_x = transforms.ToTensor()(img_x)\n",
        "        noise = torch.randn(img_x.size()).mul_(self.sigma/255.0)\n",
        "        img_y = img_x + noise\n",
        "\n",
        "        return img_y, img_x, file\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "def get_training_set(data_dir, patch_size, sigma, ch):\n",
        "    return DatasetFromFolder(data_dir, patch_size, sigma, ch)\n",
        "\n",
        "def get_eval_set(data_dir1, sigma, ch):\n",
        "    return DatasetFromFolderEval(data_dir1, sigma, ch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hY_92jG8LHC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class DnCNN(nn.Module):\n",
        "    def __init__(self, args, use_bnorm=True):\n",
        "        super(DnCNN, self).__init__()\n",
        "        padding = 1\n",
        "        layers = []\n",
        "\n",
        "        layers.append(nn.Conv2d(in_channels=args.image_channels, out_channels=args.n_channels, kernel_size=args.kernel_size, padding=padding, bias=True))\n",
        "        layers.append(nn.ReLU(inplace=True))\n",
        "        for _ in range(args.depth-2):\n",
        "            layers.append(nn.Conv2d(in_channels=args.n_channels, out_channels=args.n_channels, kernel_size=args.kernel_size, padding=padding, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(args.n_channels, eps=0.0001, momentum = 0.9))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "        layers.append(nn.Conv2d(in_channels=args.n_channels, out_channels=args.image_channels, kernel_size=args.kernel_size, padding=padding, bias=False))\n",
        "        self.dncnn = nn.Sequential(*layers)\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = x\n",
        "        out = self.dncnn(x)\n",
        "        return y-out\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                init.orthogonal_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                init.constant_(m.weight, 1)\n",
        "                init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K010XVqm8L1U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "0550445b-f323-4b09-a75a-6924d3c680c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(batch_size=32, sigma=25, lr=0.0001, start_iter=1, nEpochs=100, patch_size=128, snapshots=10, pretrained=False, gpu_mode=True, threads=1, seed=123, gpus=1, model_type='DnCNN', depth=17, n_channels=64, image_channels=3, kernel_size=3, data_dir='/content/drive/MyDrive/denoise_dataset/train', save_folder='/content/drive/MyDrive/weights/denoising/')\n",
            "===> Loading datasets\n",
            "===> Building model  DnCNN\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===> Epoch[1](0/15): Loss: 0.5064 || Timer: 1.8308 sec.\n",
            "===> Epoch[1](1/15): Loss: 0.4670 || Timer: 0.0176 sec.\n",
            "===> Epoch[1](2/15): Loss: 0.4346 || Timer: 0.0088 sec.\n",
            "===> Epoch[1](3/15): Loss: 0.3992 || Timer: 0.0151 sec.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-69f5a0dfbdaf>\u001b[0m in \u001b[0;36m<cell line: 78>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEpochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnEpochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-69f5a0dfbdaf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===> Epoch {} Complete: Avg. Loss: {:.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    963\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_meta\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__format__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "\n",
        "parser = argparse.ArgumentParser(description='DnCNN network for Denoising')\n",
        "parser.add_argument('--batch_size', type=int, default=32, help='training batch size')\n",
        "parser.add_argument('--sigma', type=int, default=25, help='noise level')\n",
        "parser.add_argument('--lr', type=float, default=1e-4, help='initial learning rate')\n",
        "parser.add_argument('--start_iter', type=int, default=1, help='the starting epoch count')\n",
        "parser.add_argument('--nEpochs', type=int, default=100, help='# of iter at starting learning rate')\n",
        "parser.add_argument('--patch_size', type=int, default=128, help='patch size')\n",
        "parser.add_argument('--snapshots', type=int, default=10, help='save weight file cycle')\n",
        "\n",
        "parser.add_argument('--pretrained', type=bool, default=False, help='Is pretrained')\n",
        "parser.add_argument('--gpu_mode', type=bool, default=True, help='GPU mode')\n",
        "parser.add_argument('--threads', type=int, default=1, help='threads')\n",
        "parser.add_argument('--seed', type=int, default=123, help='random seed to use')\n",
        "parser.add_argument('--gpus', type=int, default=1, help='GPU nums')\n",
        "\n",
        "parser.add_argument('--model_type', default='DnCNN', help='model name')\n",
        "parser.add_argument('--depth', type=int, default=17, help='depth of network')\n",
        "parser.add_argument('--n_channels', type=int, default=64, help='number of feature maps')\n",
        "parser.add_argument('--image_channels', type=int, default=3, help='number of channels')\n",
        "parser.add_argument('--kernel_size', type=int, default=3, help='kernel size')\n",
        "\n",
        "parser.add_argument('--data_dir', type=str, default='/content/drive/MyDrive/denoise_dataset/train', help='dataset directory') #이 경로 설정은 본인 컴퓨터대로 해야합니다.\n",
        "parser.add_argument('--save_folder', type=str, default='/content/drive/MyDrive/weights/denoising/', help='weight file save location') #이 경로 설정은 본인 컴퓨터대로 해야합니다.\n",
        "args = parser.parse_args('')\n",
        "\n",
        "gpus_list = range(args.gpus)\n",
        "cudnn.benchmark = True\n",
        "print(args)\n",
        "\n",
        "def train(epoch):\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for iteration, batch in enumerate(training_data_loader):\n",
        "        img_y, img_x = Variable(batch[0]), Variable(batch[1])\n",
        "        if cuda:\n",
        "            img_y = img_y.cuda(gpus_list[0])\n",
        "            img_x = img_x.cuda(gpus_list[0])\n",
        "\n",
        "        optimizer.zero_grad()  #gradient를 초기에 0으로 설정\n",
        "        t0 = time.time()\n",
        "\n",
        "        prediction = model(img_y)\n",
        "\n",
        "        loss = criterion(prediction, img_x)\n",
        "\n",
        "        t1 = time.time()\n",
        "        epoch_loss += loss.data\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f} || Timer: {:.4f} sec.\".format(epoch, iteration, len(training_data_loader), loss.data, (t1 - t0)))\n",
        "\n",
        "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(training_data_loader)))\n",
        "\n",
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)\n",
        "\n",
        "def checkpoint(epoch):\n",
        "    model_out_path = args.save_folder+\"epoch_{}.pth\".format(epoch)\n",
        "    torch.save(model.state_dict(), model_out_path)\n",
        "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    if not os.path.exists(args.save_folder):\n",
        "        os.makedirs(args.save_folder)\n",
        "\n",
        "    cuda = args.gpu_mode\n",
        "    if cuda and not torch.cuda.is_available():\n",
        "        raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "    torch.manual_seed(args.seed)\n",
        "    if cuda:\n",
        "        torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "    print('===> Loading datasets')            # dataset을 로드한다.\n",
        "    train_set = get_training_set(args.data_dir,args.patch_size, args.sigma, args.image_channels)\n",
        "    training_data_loader = DataLoader(dataset=train_set, num_workers=args.threads, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    print('===> Building model ', args.model_type)\n",
        "    if args.model_type == 'DnCNN':\n",
        "        model = DnCNN(args)\n",
        "        model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
        "\n",
        "    criterion = nn.L1Loss()\n",
        "\n",
        "    if args.pretrained:\n",
        "        model_name = args.save_folder + \"epoch_{}.pth\".format(args.start_iter - 1)\n",
        "        if os.path.exists(model_name):\n",
        "            model.load_state_dict(torch.load(model_name, map_location=lambda storage, loc: storage))\n",
        "            print('Pre-trained Denoising model is loaded.')\n",
        "\n",
        "    if cuda:\n",
        "        model = model.cuda(gpus_list[0])\n",
        "        criterion = criterion.cuda(gpus_list[0])\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9, 0.999), eps=1e-8) # gradient 조절\n",
        "\n",
        "    for epoch in range(args.start_iter, args.nEpochs + 1):\n",
        "        train(epoch)\n",
        "\n",
        "        if (epoch) % (args.nEpochs) == 0:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] /= 10.0\n",
        "            print('Learning rate decay: lr={}'.format(optimizer.param_groups[0]['lr']))\n",
        "\n",
        "        if (epoch) % (args.snapshots) == 0:\n",
        "            checkpoint(epoch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQJ5ABLXoKn-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be2abdd7-d7a3-4efc-a7e0-b89c939fc0f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(test_batch_size=1, sigma=25, gpu_mode=True, threads=1, seed=123, gpus=1, model='/content/drive/MyDrive/weights/denoising/epoch_10.pth', model_type='DnCNN', depth=17, n_channels=64, image_channels=3, kernel_size=3, data_dir='/content/drive/MyDrive/denoise_dataset/test', save_folder='/content/drive/MyDrive/result/denoising/')\n",
            "===> Loading datasets\n",
            "===> Building model\n",
            "Pre-trained Denoising model is loaded.\n",
            "===> Processing: 0802x2.png || Timer: 0.3003 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0802x2.png\n",
            "===> Processing: 0839x2.png || Timer: 0.2065 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0839x2.png\n",
            "===> Processing: 0833x2.png || Timer: 0.2375 sec. L1 : 0.0784 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0833x2.png\n",
            "===> Processing: 0824x2.png || Timer: 0.1935 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0824x2.png\n",
            "===> Processing: 0830x2.png || Timer: 0.1112 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0830x2.png\n",
            "===> Processing: 0823x2.png || Timer: 0.2003 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0823x2.png\n",
            "===> Processing: 0814x2.png || Timer: 0.1929 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0814x2.png\n",
            "===> Processing: 0801x2.png || Timer: 0.1932 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0801x2.png\n",
            "===> Processing: 0803x2.png || Timer: 0.2207 sec. L1 : 0.0802 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0803x2.png\n",
            "===> Processing: 0881x2.png || Timer: 0.1795 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0881x2.png\n",
            "===> Processing: 0898x2.png || Timer: 0.1954 sec. L1 : 0.0790 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0898x2.png\n",
            "===> Processing: 0886x2.png || Timer: 0.1921 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0886x2.png\n",
            "===> Processing: 0896x2.png || Timer: 0.1940 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0896x2.png\n",
            "===> Processing: 0900x2.png || Timer: 0.1625 sec. L1 : 0.0787 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0900x2.png\n",
            "===> Processing: 0808x2.png || Timer: 0.1949 sec. L1 : 0.0786 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0808x2.png\n",
            "===> Processing: 0807x2.png || Timer: 0.1595 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0807x2.png\n",
            "===> Processing: 0853x2.png || Timer: 0.1930 sec. L1 : 0.0809 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0853x2.png\n",
            "===> Processing: 0863x2.png || Timer: 0.2310 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0863x2.png\n",
            "===> Processing: 0862x2.png || Timer: 0.1937 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0862x2.png\n",
            "===> Processing: 0851x2.png || Timer: 0.1913 sec. L1 : 0.0786 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0851x2.png\n",
            "===> Processing: 0857x2.png || Timer: 0.2028 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0857x2.png\n",
            "===> Processing: 0846x2.png || Timer: 0.1960 sec. L1 : 0.0785 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0846x2.png\n",
            "===> Processing: 0806x2.png || Timer: 0.1955 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0806x2.png\n",
            "===> Processing: 0854x2.png || Timer: 0.1511 sec. L1 : 0.0782 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0854x2.png\n",
            "===> Processing: 0877x2.png || Timer: 0.1688 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0877x2.png\n",
            "===> Processing: 0852x2.png || Timer: 0.1703 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0852x2.png\n",
            "===> Processing: 0805x2.png || Timer: 0.2168 sec. L1 : 0.0781 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0805x2.png\n",
            "===> Processing: 0868x2.png || Timer: 0.1966 sec. L1 : 0.0780 || PSNR :   68\n",
            "Image saved as /content/drive/MyDrive/result/denoising/0868x2.png\n",
            "===> Processing: 0844x2.png || Timer: 0.1998 sec. L1 : 0.0797 || PSNR :   68\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f9fb1374f69e>\u001b[0m in \u001b[0;36m<cell line: 111>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-f9fb1374f69e>\u001b[0m in \u001b[0;36meval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===> Processing: %s || Timer: %.4f sec. L1 : %.4f || PSNR : %4.f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpsnr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0msave_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0maverage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_L1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0maverage_psnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_psnr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f9fb1374f69e>\u001b[0m in \u001b[0;36msave_img\u001b[0;34m(image_tensor, filename)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image saved as {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, fp, format, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;31m# Add 0.5 after unnormalizing to [0, 255] to round to the nearest integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import cv2\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from functools import reduce\n",
        "from math import log10\n",
        "\n",
        "parser = argparse.ArgumentParser(description='DnCNN network for Denoising')\n",
        "parser.add_argument('--test_batch_size', type=int, default=1, help='test batch size')\n",
        "parser.add_argument('--sigma', type=int, default=25, help='noise level')\n",
        "parser.add_argument('--gpu_mode', type=bool, default=True, help='GPU mode')\n",
        "parser.add_argument('--threads', type=int, default=1, help='threads')\n",
        "parser.add_argument('--seed', type=int, default=123, help='random seed to use')\n",
        "parser.add_argument('--gpus', type=int, default=1, help='GPU nums')\n",
        "parser.add_argument('--model', type=str, default=\"/content/drive/MyDrive/weights/denoising/epoch_10.pth\", help='weight file location')\n",
        "\n",
        "parser.add_argument('--model_type', default='DnCNN', help='model name')\n",
        "parser.add_argument('--depth', type=int, default=17, help='depth of network')\n",
        "parser.add_argument('--n_channels', type=int, default=64, help='number of feature maps')\n",
        "parser.add_argument('--image_channels', type=int, default=3, help='number of channels')\n",
        "parser.add_argument('--kernel_size', type=int, default=3, help='kernel size')\n",
        "\n",
        "parser.add_argument('--data_dir', type=str, default='/content/drive/MyDrive/denoise_dataset/test', help='dataset directory')\n",
        "parser.add_argument('--save_folder', type=str, default='/content/drive/MyDrive/result/denoising/', help='result file save location')\n",
        "args = parser.parse_args('')\n",
        "\n",
        "gpus_list=range(args.gpus)\n",
        "print(args)\n",
        "\n",
        "cuda = args.gpu_mode\n",
        "if cuda and not torch.cuda.is_available():\n",
        "    raise Exception(\"No GPU found, please run without --cuda\")\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "criterion = nn.L1Loss()\n",
        "\n",
        "print('===> Loading datasets')\n",
        "test_set = get_eval_set(args.data_dir,args.sigma,args.image_channels)\n",
        "testing_data_loader = DataLoader(dataset=test_set, num_workers=args.threads, batch_size=args.test_batch_size, shuffle=False)\n",
        "\n",
        "print('===> Building model')\n",
        "model = DnCNN(args)\n",
        "model = torch.nn.DataParallel(model, device_ids=gpus_list)\n",
        "\n",
        "model.load_state_dict(torch.load(args.model, map_location=lambda storage, loc: storage))\n",
        "print('Pre-trained Denoising model is loaded.')\n",
        "\n",
        "if cuda:\n",
        "    model = model.cuda(gpus_list[0])\n",
        "    criterion = criterion.cuda(gpus_list[0])\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    img1 , img2 = img1.cpu().numpy(), img2.cpu().numpy()\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1.0 if img1.max() <= 1.0 else 255.0\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "def eval():\n",
        "    avg_L1 = 0\n",
        "    L1_sq = 0\n",
        "    average = 0\n",
        "    variance = 0\n",
        "    avg_psnr = 0\n",
        "\n",
        "    model.eval()\n",
        "    for batch in testing_data_loader:\n",
        "        with torch.no_grad():\n",
        "            img_y, img_x, name = Variable(batch[0]), Variable(batch[1]), batch[2]\n",
        "\n",
        "        if cuda:\n",
        "            img_y = img_y.cuda(gpus_list[0])\n",
        "            img_x = img_x.cuda(gpus_list[0])\n",
        "\n",
        "        t0 = time.time()\n",
        "        with torch.no_grad():\n",
        "          prediction = model(img_y)\n",
        "\n",
        "        L1 = criterion(prediction, img_x)\n",
        "        psnr = calculate_psnr(prediction, img_x)\n",
        "        avg_L1 += L1\n",
        "        avg_psnr += psnr\n",
        "\n",
        "        t1 = time.time()\n",
        "        print(\"===> Processing: %s || Timer: %.4f sec. L1 : %.4f || PSNR : %4.f\" % (name[0], (t1 - t0), L1, psnr))\n",
        "        prediction = prediction.squeeze(0).cpu()\n",
        "        save_img(prediction, name[0])\n",
        "        average = avg_L1/len(testing_data_loader)\n",
        "        average_psnr = avg_psnr / len(testing_data_loader)\n",
        "    print(\"===> Processing Done, Average L1 : %.4f || Average PSNR : %4.f\" % (average, average_psnr))\n",
        "\n",
        "def save_img(image_tensor, filename):\n",
        "    save_dir = args.save_folder\n",
        "\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    save_image(image_tensor, save_dir+filename)\n",
        "    print(\"Image saved as {}\".format(save_dir+filename))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    eval()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}